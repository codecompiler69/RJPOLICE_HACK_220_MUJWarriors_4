{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Offense</th>\n",
       "      <th>Punishment</th>\n",
       "      <th>Cognizable</th>\n",
       "      <th>Bailable</th>\n",
       "      <th>Court</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lawrato.com/indian-kanoon/ipc/section-140</td>\n",
       "      <td>Description of IPC Section 140\\nAccording to s...</td>\n",
       "      <td>Wearing the dress or carrying any token used b...</td>\n",
       "      <td>3 Months or Fine or Both</td>\n",
       "      <td>Cognizable</td>\n",
       "      <td>Bailable</td>\n",
       "      <td>Any Magistrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lawrato.com/indian-kanoon/ipc/section-127</td>\n",
       "      <td>Description of IPC Section 127\\nAccording to s...</td>\n",
       "      <td>Receiving property taken by war or depredation...</td>\n",
       "      <td>7 Years + Fine + forfeiture of property</td>\n",
       "      <td>Cognizable</td>\n",
       "      <td>Non-Bailable</td>\n",
       "      <td>Court of Session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lawrato.com/indian-kanoon/ipc/section-128</td>\n",
       "      <td>Description of IPC Section 128\\nAccording to s...</td>\n",
       "      <td>Public servant voluntarily allowing prisoner o...</td>\n",
       "      <td>Imprisonment for Life or 10 Years + Fine</td>\n",
       "      <td>Cognizable</td>\n",
       "      <td>Non-Bailable</td>\n",
       "      <td>Court of Session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lawrato.com/indian-kanoon/ipc/section-129</td>\n",
       "      <td>Description of IPC Section 129\\nAccording to s...</td>\n",
       "      <td>Public servant negligently suffering prisoner ...</td>\n",
       "      <td>Simple Imprisonment 3 Years + Fine</td>\n",
       "      <td>Cognizable</td>\n",
       "      <td>Bailable</td>\n",
       "      <td>Magistrate First Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lawrato.com/indian-kanoon/ipc/section-130</td>\n",
       "      <td>Description of IPC Section 130\\nAccording to s...</td>\n",
       "      <td>Aiding escape of, rescuing or harbouring, such...</td>\n",
       "      <td>Imprisonment for Life or 10 Years + Fine</td>\n",
       "      <td>Cognizable</td>\n",
       "      <td>Non-Bailable</td>\n",
       "      <td>Court of Session</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://lawrato.com/indian-kanoon/ipc/section-140   \n",
       "1  https://lawrato.com/indian-kanoon/ipc/section-127   \n",
       "2  https://lawrato.com/indian-kanoon/ipc/section-128   \n",
       "3  https://lawrato.com/indian-kanoon/ipc/section-129   \n",
       "4  https://lawrato.com/indian-kanoon/ipc/section-130   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Description of IPC Section 140\\nAccording to s...   \n",
       "1  Description of IPC Section 127\\nAccording to s...   \n",
       "2  Description of IPC Section 128\\nAccording to s...   \n",
       "3  Description of IPC Section 129\\nAccording to s...   \n",
       "4  Description of IPC Section 130\\nAccording to s...   \n",
       "\n",
       "                                             Offense  \\\n",
       "0  Wearing the dress or carrying any token used b...   \n",
       "1  Receiving property taken by war or depredation...   \n",
       "2  Public servant voluntarily allowing prisoner o...   \n",
       "3  Public servant negligently suffering prisoner ...   \n",
       "4  Aiding escape of, rescuing or harbouring, such...   \n",
       "\n",
       "                                 Punishment  Cognizable      Bailable  \\\n",
       "0                  3 Months or Fine or Both  Cognizable      Bailable   \n",
       "1   7 Years + Fine + forfeiture of property  Cognizable  Non-Bailable   \n",
       "2  Imprisonment for Life or 10 Years + Fine  Cognizable  Non-Bailable   \n",
       "3        Simple Imprisonment 3 Years + Fine  Cognizable      Bailable   \n",
       "4  Imprisonment for Life or 10 Years + Fine  Cognizable  Non-Bailable   \n",
       "\n",
       "                    Court  \n",
       "0          Any Magistrate  \n",
       "1        Court of Session  \n",
       "2        Court of Session  \n",
       "3  Magistrate First Class  \n",
       "4        Court of Session  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/tosar/Downloads/FIR_DATASET.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Description', 'Offense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = df['Description'].values\n",
    "y = df['Offense'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "max_words = 5000  # Adjust based on your dataset\n",
    "max_len = 100  # Adjust based on your dataset\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "embedding_dim = 50  # Adjust based on your dataset\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 5s 124ms/step - loss: 5.9367 - accuracy: 0.0036 - val_loss: 5.9423 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 5.9270 - accuracy: 0.0328 - val_loss: 5.9550 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 5.9145 - accuracy: 0.0182 - val_loss: 6.0266 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 5.8704 - accuracy: 0.0073 - val_loss: 6.9862 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 5.7752 - accuracy: 0.0036 - val_loss: 7.3227 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 5.7105 - accuracy: 0.0036 - val_loss: 7.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 5.6651 - accuracy: 0.0036 - val_loss: 8.0480 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 5.6166 - accuracy: 0.0073 - val_loss: 8.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 5.5770 - accuracy: 0.0109 - val_loss: 8.2964 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 5.5017 - accuracy: 0.0073 - val_loss: 8.4532 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x296d1b7cb90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 32  # Adjust based on your dataset\n",
    "epochs = 10  # Adjust based on your dataset\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 8.3484 - accuracy: 0.0000e+00\n",
      "Test Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 119ms/step - loss: 5.9341 - accuracy: 0.1129 - val_loss: 5.9273 - val_accuracy: 0.1667\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 5.7906 - accuracy: 0.1505 - val_loss: 5.8260 - val_accuracy: 0.1667\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 5.5079 - accuracy: 0.1505 - val_loss: 6.2364 - val_accuracy: 0.1667\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 5.3554 - accuracy: 0.1505 - val_loss: 6.6418 - val_accuracy: 0.1667\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 5.2844 - accuracy: 0.1505 - val_loss: 6.9405 - val_accuracy: 0.1667\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 5.2529 - accuracy: 0.1505 - val_loss: 7.2125 - val_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 5.2294 - accuracy: 0.1505 - val_loss: 7.4795 - val_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 5.2090 - accuracy: 0.1505 - val_loss: 7.6018 - val_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 5.1889 - accuracy: 0.1505 - val_loss: 7.6980 - val_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 5.1683 - accuracy: 0.1505 - val_loss: 7.7788 - val_accuracy: 0.1667\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.3078 - accuracy: 0.0899\n",
      "Test Accuracy: 8.99%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load your dataset\n",
    "# Assume your dataset is loaded into the variable df\n",
    "df = pd.read_csv(\"C:/Users/tosar/Downloads/FIR_DATASET.csv\")\n",
    "# Drop rows with null values in the 'Description' column\n",
    "df = df.dropna(subset=['Description'])\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df['Description'].values\n",
    "y = df['Offense'].values\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "max_words = 5000  # Adjust based on your dataset\n",
    "max_len = 100  # Adjust based on your dataset\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=max_len)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "embedding_dim = 50  # Adjust based on your dataset\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32  # Adjust based on your dataset\n",
    "epochs = 10  # Adjust based on your dataset\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
